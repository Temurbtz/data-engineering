Butaev Temur  
Report: 4.12.2023-7.12.2023

1) Spent time for learning airflow
2) Implemented airflow DAGs with different operators: BashOperator, PythonOperator
3)Spent time for  learning apache spark: why we use  apache spark, spark architecture, spark driver, spark executor, how spark works with clusters.
4) Spent time for learn APIs for apache spark such as: pyspark
5) Learned about pyspark componenets, basic operations on pyspark, working with csv files and so on.
6) Combined all knowledge and implemented basic task  with apache airflow and apache spark, which performs pyspark job in airflow.
